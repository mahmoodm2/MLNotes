{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahmoud MOhamamdi (800-8683389-mmoham12)\n",
    "## ITSC 5010- Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Classifier\n",
    "\n",
    "### Data Set : Breast Cancer\n",
    "### Address :\n",
    "    https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29\n",
    "### Feature Columns:            \n",
    "\n",
    "1.Clump_Thickness \n",
    "\n",
    "2.Cell_Size_Uniformity\n",
    "\n",
    "3.Cell_Shape_Uniformity\n",
    "\n",
    "4.Marginal_Adhesion\n",
    "\n",
    "5.Single_Epi_Cell_Size\n",
    "\n",
    "6.Bare_Nuclei\n",
    "\n",
    "7.Bland_Chromatin\n",
    "\n",
    "8.Normal_Nucleoli\n",
    "\n",
    "9.Mitoses\n",
    "\n",
    "10.Class (2 for benign, 4 for malignant)\n",
    "\n",
    "### Label Column \n",
    "    Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets.mldata import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import tempfile\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self, sess, dataset_name , n_inputs, n_outputs, \\\n",
    "                 n_neurons, scope, epoch, batch_size, learning_rate):\n",
    "\n",
    "        self.dataset = dataset_name\n",
    "        self.n_inputs= n_inputs\n",
    "        self.n_classes= n_outputs\n",
    "        #self.n_hidden = n_hidden\n",
    "        self.n_neurons = n_neurons\n",
    "        \n",
    "        self.scope= scope\n",
    "        \n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.learning_rate= learning_rate\n",
    "        \n",
    "        self.sess = sess\n",
    "        \n",
    "        # Partitioning the dataset  \n",
    "        X_data , y_labels, y_onehot = self.load_dataset(dataset_name)\n",
    "        \n",
    "        print(\" Data %s ,  Label %s , OneHot %s \" %(X_data.shape , y_labels.shape ,y_onehot.shape ))\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test \\\n",
    "            = train_test_split( X_data , y_labels, test_size = 0.2)\n",
    "            \n",
    "        \n",
    "        self.build_model()\n",
    "\n",
    "    \n",
    "    def clean_data(self, data):\n",
    "    \n",
    "        #data.fillna(0. , inplace= True)\n",
    "        data = data.astype(str)\n",
    "        \n",
    "        for col in data.columns:\n",
    "            data[col]=data[col].map(str.strip) # removing all space from the string values\n",
    "\n",
    "       \n",
    "    # age: continuous.\n",
    "        workclass_map={ 'Private':1, 'Self-emp-not-inc':2, 'Self-emp-inc':3, 'Federal-gov':4, 'Local-gov':5\n",
    "                   , 'State-gov':6, 'Without-pay':7, 'Never-worked':8 }\n",
    "    # fnlwgt: continuous.\n",
    "        education_map ={'Bachelors':1, 'Some-college':2, '11th':3, 'HS-grad':4, 'Prof-school':5, 'Assoc-acdm':6\n",
    "                    , 'Assoc-voc':7, '9th':8, '7th-8th':9, '12th':10, 'Masters':11, '1st-4th':12\n",
    "                    , '10th':13, 'Doctorate':14, '5th-6th':15, 'Preschool':16 }\n",
    "    # education-num: continuous.\n",
    "        marital_status_map={ 'Married-civ-spouse':1, 'Divorced':2, 'Never-married':3, 'Separated':4\n",
    "                        , 'Widowed':4, 'Married-spouse-absent':6, 'Married-AF-spouse':7}\n",
    "        occupation_map={ 'Tech-support':1, 'Craft-repair':2, 'Other-service':3, 'Sales':4, 'Exec-managerial':5\n",
    "                    , 'Prof-specialty':6, 'Handlers-cleaners':7, 'Machine-op-inspct':8, 'Adm-clerical':9\n",
    "                    , 'Farming-fishing':10, 'Transport-moving':11, 'Priv-house-serv':12\n",
    "                    , 'Protective-serv':13, 'Armed-Forces':14}\n",
    "        relationship_map={ 'Wife':1, 'Own-child':2, 'Husband':3, 'Not-in-family':4, 'Other-relative':5, 'Unmarried':6}\n",
    "        race_map ={'White':1, 'Asian-Pac-Islander':2, 'Amer-Indian-Eskimo':3, 'Other':4, 'Black':5}\n",
    "        sex_map={'Female':1, 'Male':2}\n",
    "        # capital-gain: continuous.\n",
    "        # capital-loss: continuous.\n",
    "        # hours-per-week: continuous.\n",
    "        native_country_map ={'United-States':1, 'Cambodia':2, 'England':3, 'Puerto-Rico':4, 'Canada':5\n",
    "                             , 'Germany':6, 'Outlying-US(Guam-USVI-etc)':7, 'India':8, 'Japan':9, 'Greece':10\n",
    "                             , 'South':11, 'China':12, 'Cuba':13, 'Iran':14, 'Honduras':15, 'Philippines':16\n",
    "                             , 'Italy':17, 'Poland':18, 'Jamaica':19, 'Vietnam':20, 'Mexico':21\n",
    "                             , 'Portugal':21, 'Ireland':22\n",
    "                             , 'France':23, 'Dominican-Republic':24, 'Laos':25, 'Ecuador':26\n",
    "                             , 'Taiwan':27, 'Haiti':28, 'Columbia':29\n",
    "                             , 'Hungary':30, 'Guatemala':31, 'Nicaragua':32, 'Scotland':33\n",
    "                             , 'Thailand':34, 'Yugoslavia':35\n",
    "                             , 'El-Salvador':36, 'Trinadad&Tobago':37, 'Peru':38, 'Hong':39, 'Holand-Netherlands':40}\n",
    "\n",
    "        label_map={'<=50K':0, '>50K':1}\n",
    "        \n",
    "        theregex = re.compile(r'[^\\d.-]+')\n",
    "\n",
    "        data.replace(to_replace='?', value ='0') \n",
    "\n",
    "        data.replace(inplace =True ,to_replace = {'workclass':workclass_map \n",
    "        ,'education':education_map\n",
    "                         ,'marital-status':marital_status_map \n",
    "                         ,'occupation':occupation_map , 'relationship':relationship_map\n",
    "                          ,'race':race_map , 'sex':sex_map ,'native-country':native_country_map\n",
    "                            ,'label': label_map\n",
    "                         } )\n",
    "\n",
    "        data = data.astype('str').applymap(lambda x: re.sub(r'[^\\d.]+', '0', x))  \n",
    "\n",
    "        data = data.astype('int')\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    def load_dataset(self, dataset_name):\n",
    "        \n",
    "              \n",
    "        url =\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "        columns=['age' , 'workclass' ,'fnlwgt','education' ,'education-num','marital-status' ,'occupation', 'relationship'\n",
    "            ,'race' , 'sex' ,'capital-gain' ,'capital-loss' ,'hours-per-week' ,'native-country','label']\n",
    "\n",
    "        all_data = pd.read_csv(url , header= None , names=columns, index_col=None)\n",
    "        \n",
    "        all_data=all_data[:10000]\n",
    "        \n",
    "        all_data.reset_index()\n",
    "        print(all_data.shape)\n",
    "        \n",
    "        cleaned_data = self.clean_data(all_data)\n",
    "        \n",
    "        \n",
    "#         col_names = \"id,clump_thickness,unif_cell_size,unif_cell_shape,marg_adhesion,single_epith_cell_size,bare_nuclei,bland_chrom,norm_nucleoli,mitoses,class\"\n",
    "        \n",
    "#         col_names= col_names.split(',')\n",
    "        \n",
    "#         base_dir = '/home/mmoham12/Projects/DeepLearningHW/'\n",
    "    \n",
    "#         df = pd.read_csv(base_dir + data_file, names= col_names)\n",
    "\n",
    "#         df.replace('?', np.nan, inplace = True)\n",
    "#         df.dropna(inplace=True)\n",
    "#         df.drop(['id'], axis = 1, inplace = True)\n",
    "\n",
    "#         df['class'].replace('2',0, inplace = True)\n",
    "#         df['class'].replace('4',1, inplace = True)\n",
    "        \n",
    "#         df['bare_nuclei'] = pd.to_numeric(df['bare_nuclei'])\n",
    "\n",
    "#         #df.to_csv(\"cleaned_data.csv\", index = False)\n",
    "\n",
    "        y= np.array(cleaned_data['label'], dtype= np.int)\n",
    "               \n",
    "        X = np.array(cleaned_data.drop('label', axis =1), dtype= np.float)\n",
    "             \n",
    "       \n",
    "        y = y.reshape(y.shape[0])\n",
    "        \n",
    "#         if dataset_name == 'breast-cancer':\n",
    "#             y[y==2]= 0 \n",
    "#             y[y==4]= 1\n",
    "        \n",
    "        y_onehot = np.zeros( (len(y) , self.n_classes), dtype=np.float)\n",
    "        \n",
    "        for i, lbl in enumerate(y):\n",
    "            y_onehot[i, y[i]] = 1.0\n",
    "            \n",
    "        return X, y , y_onehot# data , labels\n",
    "        \n",
    "      \n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        with tf.name_scope(self.scope) :\n",
    "            \n",
    "            inputs_dim= [self.n_inputs]\n",
    "            \n",
    "            y_dim = []\n",
    "            \n",
    "            self.inputs= tf.placeholder(tf.float32, shape=[None] + inputs_dim,  name='inputs')\n",
    "            \n",
    "            self.y = tf.placeholder(tf.float32, shape=[None] + y_dim, name='y')\n",
    "\n",
    "           # print(\"self.X_train %s \" %(self.X_train.shape ))\n",
    "            \n",
    "            # Hidden Layer with ReLU Activation function as default\n",
    "            \n",
    "            inputs = fully_connected(self.X_train, self.n_neurons )\n",
    "            \n",
    "            print(\"inputs %s \" %(inputs.shape ))\n",
    "            \n",
    "            hidden1 = fully_connected(inputs, self.n_neurons )\n",
    "            \n",
    "            print(\"Hidern 1 %s \" %(hidden1.shape))\n",
    "\n",
    "            # Last Layer of model without applying Activation function: Logits\n",
    "            logits = fully_connected(hidden1, self.n_classes, activation_fn=None)\n",
    "\n",
    "            # Defining Loss function based on Entropy\n",
    "            \n",
    "            print(\"Logits %s , Label %s\" %(logits.shape , self.y_train.shape))\n",
    "            \n",
    "            \n",
    "           # xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels= self.y_train , logits= logits)\n",
    "            xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits= logits ,labels= self.y_train )\n",
    "\n",
    "            self.cost = tf.reduce_mean(xentropy, name=\"cost\") # Average of all logits\n",
    "            \n",
    "            self.saver = tf.train.Saver()\n",
    "            \n",
    "            # Evaluation of Logits\n",
    "            \n",
    "            evals = tf.nn.in_top_k(tf.cast(logits , tf.float32), self.y_train, 1)\n",
    "            \n",
    "            self.accuracy = tf.reduce_mean( tf.cast(evals , tf.float32))\n",
    "\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        print(\"Start Training...\\n\")\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "               \n",
    "        tf.global_variables_initializer().run(session= self.sess)\n",
    "                    \n",
    "        num_batches = len(self.X_train) // self.batch_size \n",
    "        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.epoch):\n",
    "            \n",
    "            #print(\"Epoch Index\"+ epoch)\n",
    "            \n",
    "            for idx in range(num_batches):\n",
    "                \n",
    "                #print(\"Batch Index\"+ idx)\n",
    "                \n",
    "                batch_data = self.X_train[idx *  self.batch_size: (idx+1) *  self.batch_size] \n",
    "                batch_labeles= self.y_train[idx *  self.batch_size: (idx+1) *  self.batch_size] \n",
    "                \n",
    "                #print(\"Batch Data %s , Batch Label %s\" %(batch_data.shape , batch_labeles.shape))\n",
    "                \n",
    "                with self.sess.as_default():\n",
    "                    \n",
    "                    self.sess.run([optimizer],\n",
    "                        feed_dict={self.inputs: batch_data, \n",
    "                                   self.y:      batch_labeles  \n",
    "                                  })\n",
    "                \n",
    "#                     acc_train = self.accuracy.eval( feed_dict={\n",
    "#                     self.inputs: batch_data, \n",
    "#                     self.y:      batch_labeles  \n",
    "#                      })\n",
    "                \n",
    "                    acc_test  = self.accuracy.eval( feed_dict={\n",
    "                    self.inputs: self.X_test, \n",
    "                    self.y:      self.y_test  \n",
    "                                                          \n",
    "                    })\n",
    "            \n",
    "            \n",
    "            #if (epoch+1) % train_show == 0:\n",
    "\n",
    "            cost = self.cost.eval(session= sess, feed_dict= {self.inputs: self.X_train , self.y: self.y_train})\n",
    "\n",
    "\n",
    "            print (\"Epoch:[%02d], Batch :[%2d / %3d],cost= %.4f \" % ( epoch+1 ,idx+1,\\\n",
    "                 num_batches,cost))\n",
    "                \n",
    "#             print(\"Dataset:[%s]-> Epoch:[%2d], time: %4.4f, Accuracy: %.6f\"\n",
    "#                   % (self.dataset, epoch+1,\n",
    "#                      time.time() - start_time, acc_test))\n",
    "            \n",
    "#             print(\"Dataset:[%s]-> Epoch:[%2d], Batch :[%2d/%3d] time: %4.4f, Accuracy: %.6f\"\n",
    "#                   % (self.dataset, epoch+1, idx, num_batches,\n",
    "#                      time.time() - start_time, acc_test))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 15)\n",
      " Data (10000, 14) ,  Label (10000,) , OneHot (10000, 2) \n",
      "inputs (8000, 20) \n",
      "Hidern 1 (8000, 20) \n",
      "Logits (8000, 2) , Label (8000,)\n",
      "Start Training...\n",
      "\n",
      "Epoch:[01], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[02], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[03], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[04], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[05], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[06], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[07], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[08], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[09], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[10], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[11], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[12], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[13], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[14], Batch :[160 / 160],cost= 0.5514 \n",
      "Epoch:[15], Batch :[160 / 160],cost= 0.5514 \n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "        nn_obj = BaseModel(\n",
    "            sess,\n",
    "            dataset_name ='Adult',\n",
    "            scope = 'Project', \n",
    "            epoch = 15, \n",
    "            n_inputs = 14, # Adult has  14 features\n",
    "            n_outputs = 2,# Adult has  2 classes            \n",
    "            n_neurons = 20,           \n",
    "            batch_size= 50, \n",
    "            learning_rate = 0.1\n",
    "            )\n",
    "        \n",
    "nn_obj.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
